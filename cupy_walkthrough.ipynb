{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "import numpy as np\n",
    "assert cp.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cp.array([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy\n",
    "import torch\n",
    "\n",
    "cupy_custom_kernel_fwd = cupy.RawKernel(\n",
    "    r\"\"\"\n",
    "extern \"C\" __global__\n",
    "void cupy_custom_kernel_fwd(const float* x, float* y, int size) {\n",
    "    int tid = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "    if (tid < size)\n",
    "        y[tid] = log(x[tid]);\n",
    "}\n",
    "\"\"\",\n",
    "    \"cupy_custom_kernel_fwd\",\n",
    ")\n",
    "\n",
    "\n",
    "cupy_custom_kernel_bwd = cupy.RawKernel(\n",
    "    r\"\"\"\n",
    "extern \"C\" __global__\n",
    "void cupy_custom_kernel_bwd(const float* x, float* gy, float* gx, int size) {\n",
    "    int tid = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "    if (tid < size)\n",
    "        gx[tid] = gy[tid] / x[tid];\n",
    "}\n",
    "\"\"\",\n",
    "    \"cupy_custom_kernel_bwd\",\n",
    ")\n",
    "\n",
    "\n",
    "class CuPyLog(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        ctx.input = x\n",
    "        # Enforce contiguous arrays to simplify RawKernel indexing.\n",
    "        cupy_x = cupy.ascontiguousarray(cupy.from_dlpack(x.detach()))\n",
    "        cupy_y = cupy.empty(cupy_x.shape, dtype=cupy_x.dtype)\n",
    "        x_size = cupy_x.size\n",
    "        bs = 128\n",
    "        cupy_custom_kernel_fwd(\n",
    "            (bs,), ((x_size + bs - 1) // bs,), (cupy_x, cupy_y, x_size)\n",
    "        )\n",
    "        # the ownership of the device memory backing cupy_y is implicitly\n",
    "        # transferred to torch_y, so this operation is safe even after\n",
    "        # going out of scope of this function.\n",
    "        torch_y = torch.from_dlpack(cupy_y)\n",
    "        return torch_y\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_y):\n",
    "        # Enforce contiguous arrays to simplify RawKernel indexing.\n",
    "        cupy_input = cupy.from_dlpack(ctx.input.detach()).ravel()\n",
    "        cupy_grad_y = cupy.from_dlpack(grad_y.detach()).ravel()\n",
    "        cupy_grad_x = cupy.zeros(cupy_grad_y.shape, dtype=cupy_grad_y.dtype)\n",
    "        gy_size = cupy_grad_y.size\n",
    "        bs = 128\n",
    "        cupy_custom_kernel_bwd(\n",
    "            (bs,),\n",
    "            ((gy_size + bs - 1) // bs,),\n",
    "            (cupy_input, cupy_grad_y, cupy_grad_x, gy_size),\n",
    "        )\n",
    "        # the ownership of the device memory backing cupy_grad_x is implicitly\n",
    "        # transferred to torch_y, so this operation is safe even after\n",
    "        # going out of scope of this function.\n",
    "        torch_grad_x = torch.from_dlpack(cupy_grad_x)\n",
    "        return torch_grad_x\n",
    "    \n",
    "    \n",
    "inp = torch.randn(10).cuda()\n",
    "outp = CuPyLog.apply(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    nan,     nan, -0.8041,     nan,  0.3397,     nan,     nan,     nan,\n",
       "        -2.3179,     nan], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(3.74165739)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp.linalg.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<CUDA Device 0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with cp.cuda.Device(0):\n",
    "    x = cp.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<CUDA Device 0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from cupy import ElementwiseKernel\n",
    "\n",
    "squared_diff = cp.ElementwiseKernel(\n",
    "    'float32 x, float32 y',\n",
    "    'float32 z',\n",
    "    'z = (x - y) * (x - y)',\n",
    "    'squared_diff'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.],\n",
       "       [25., 25., 25., 25., 25.]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xp = cp.arange(10, dtype=np.float32).reshape(2,5)\n",
    "yp = cp.arange(5, dtype=np.float32)\n",
    "\n",
    "squared_diff(xp, yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "squared_diff_generic = cp.ElementwiseKernel(\n",
    "    'T x, T y',\n",
    "    'T z',\n",
    "    'z = (x - y) * (x - y)',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.],\n",
       "       [25., 25., 25., 25., 25.]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squared_diff_generic(xp, yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  2.,  4.,  6.,  8., 10., 12., 14., 16., 18.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "kernel = cp.RawKernel(\n",
    "    r\"\"\"\n",
    "    extern \"C\" __global__\n",
    "    void kernel(double* x, double* y, double* z) {\n",
    "        const int tx = threadIdx.x;\n",
    "        const int gx = tx + blockIdx.x * blockDim.x;\n",
    "        z[gx] = x[gx] + y[gx];\n",
    "    }\n",
    "    \"\"\",\n",
    "    'kernel'\n",
    ")\n",
    "\n",
    "xp = cp.arange(10, dtype='float64')\n",
    "yp = cp.arange(10, dtype='float64')\n",
    "zp = cp.empty_like(xp)\n",
    "\n",
    "n = len(xp)\n",
    "THREADS_PER_BLOCK = (4,1,1)\n",
    "BLOCKS_PER_GRID = (math.ceil(n / THREADS_PER_BLOCK[0]), 1, 1)\n",
    "kernel(\n",
    "    BLOCKS_PER_GRID, THREADS_PER_BLOCK,\n",
    "    (xp,yp,zp)\n",
    ")\n",
    "zp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
